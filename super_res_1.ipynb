{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2592,
     "status": "ok",
     "timestamp": 1549968514387,
     "user": {
      "displayName": "Ishan Shukla",
      "photoUrl": "",
      "userId": "07111032317237931620"
     },
     "user_tz": -330
    },
    "id": "UDSgHscUupeE",
    "outputId": "34737727-4158-47e8-8fb8-61086612cd5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from skimage import io\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(2)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import h5py\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2577,
     "status": "ok",
     "timestamp": 1549968514390,
     "user": {
      "displayName": "Ishan Shukla",
      "photoUrl": "",
      "userId": "07111032317237931620"
     },
     "user_tz": -330
    },
    "id": "aaFi8h4LupeJ",
    "outputId": "dfbc296a-d684-4f1c-9f53-4c23a169e8b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (100,) (5,) (5,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Args:\n",
    "    base: base folder name in which files are located\n",
    "    SRF: image_SRF folder to select\n",
    "    n_ids: number of ids to generated from 1...n_ids\n",
    "Returns:\n",
    "    A numpy character array of filenames\n",
    "\"\"\"\n",
    "def gen_filenames_labels(base, SRF, n_ids):\n",
    "    basepath = base + SRF\n",
    "    \n",
    "    dataset_arr = np.chararray(shape=(n_ids, 2), itemsize=128)\n",
    "    \n",
    "    for i in range(1, n_ids+1):\n",
    "        Y = basepath + 'img_{:03}_SRF_2_HR.png'.format(i)\n",
    "        X = basepath + 'img_{:03}_SRF_2_bicubic.png'.format(i)\n",
    "        X_dash = basepath + 'img_{:03}_SRF_2_LR.png'.format(i)\n",
    "        \n",
    "        dataset_arr[i-1, 0] = X_dash\n",
    "        dataset_arr[i-1, 1] = Y\n",
    "    \n",
    "    return dataset_arr\n",
    "\n",
    "dataset = gen_filenames_labels('train/', 'image_SRF_2/', 100)\n",
    "val_dataset = gen_filenames_labels('Set14/', 'image_SRF_2/', 5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = dataset[:, 0], val_dataset[:, 0], dataset[:, 1], val_dataset[:, 1]\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BgC3gPnbupeN"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class to store parameters which would be required to build and train model\n",
    "\"\"\"\n",
    "\n",
    "class ModelParameters:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.input_height = 32\n",
    "        self.input_width = 32\n",
    "        self.label_height = 64\n",
    "        self.label_width = 64\n",
    "        self.n_channels = 1\n",
    "        self.n_epochs = 30\n",
    "        self.learning_rate = 0.1\n",
    "        self.decay_rate = 0.9\n",
    "        self.decay_steps = 10000\n",
    "\n",
    "params = ModelParameters()\n",
    "\n",
    "'''\n",
    "def decode_ycbcr(image):\n",
    "    Y = image[0]\n",
    "    Cr = image[1]\n",
    "    Cb = image[2]\n",
    "    \n",
    "    delta = 0.5\n",
    "    \n",
    "    R = Y + 1.403 * (Cr - delta)\n",
    "    G = Y - 0.714 * (Cr - delta) - 0.344 * (Cb - delta)\n",
    "    B = Y + 1.779 * (Cb - delta)\n",
    "    \n",
    "    ycrcb = np.array([R,G,B])\n",
    "    \n",
    "    rgb[0], rgb[1], rgb[2] = R, G, B\n",
    "    return image\n",
    "'''\n",
    "\n",
    "def encode_ycbcr(image):\n",
    "    R = image[:, :, 0]\n",
    "    G = image[:, :, 1]\n",
    "    B = image[:, :, 2]\n",
    "    \n",
    "    delta = 0.5\n",
    "    \n",
    "    Y = tf.add(tf.add(tf.multiply(0.299, R), tf.multiply(0.587, G)), tf.multiply(0.114, B))\n",
    "    Cr = tf.add(tf.multiply(tf.subtract(R, Y),0.713), delta)\n",
    "    Cb = tf.add(tf.multiply(tf.subtract(B, Y), 0.564), delta)\n",
    "    \n",
    "    img = tf.stack([Y, Cr, Cb], axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Builds a tensorflow graph to be used for loading files into memory. ETL process\n",
    "\n",
    "Args:\n",
    "    filename: filename\n",
    "    ksizes: A list of ints that has length >= 4. \n",
    "            The size of the sliding window for each dimension of images\n",
    "    strides: A list of ints that has length >= 4. \n",
    "            1-D of length 4. How far the centers of two consecutive patches are in the images. \n",
    "            Must be: [1, stride_rows, stride_cols, 1].\n",
    "    rates: A list of ints that has length >= 4. 1-D of length 4. \n",
    "            Must be: [1, rate_rows, rate_cols, 1]. \n",
    "            This is the input stride, specifying how far two consecutive patch samples are in the input. \n",
    "            Equivalent to extracting patches with patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1), \n",
    "            followed by subsampling them spatially by a factor of rates. \n",
    "            This is equivalent to rate in dilated (a.k.a. Atrous) convolutions.\n",
    "            \n",
    "Returns:\n",
    "    Batch of patches extracted from the image.\n",
    "\"\"\"\n",
    "def get_img_from_file(filename, ksizes, kstrides, rates, height, width, channels, color_space='YCbCr'):\n",
    "    file = tf.read_file(filename)\n",
    "    img = tf.image.decode_png(file, channels=3)\n",
    "    \n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    \n",
    "    if color_space is 'YCbCr':\n",
    "        img = encode_ycbcr(img)[:, :, 0:1]\n",
    "        \n",
    "    assert(img.get_shape().as_list()[2] is 1)\n",
    "    \n",
    "    #img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    patches = tf.image.extract_image_patches(tf.expand_dims(img, 0), \n",
    "                                             ksizes, \n",
    "                                             kstrides, \n",
    "                                             rates, \n",
    "                                             padding='VALID')\n",
    "\n",
    "    input_img_batch = tf.squeeze(patches)\n",
    "    shape = tf.shape(input_img_batch)\n",
    "    input_img_batch = tf.reshape(input_img_batch, [shape[0]*shape[1], \n",
    "                                                   height, \n",
    "                                                   width, \n",
    "                                                   channels])\n",
    "    return input_img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sXDJ3HZupeQ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A class for building graph that loads and initializes iterators for loading data into graph\n",
    "\"\"\"\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, params):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.params = params\n",
    "        self.in_ksizes = [1, params.input_height, params.input_width, 1]\n",
    "        self.out_ksizes = [1, params.label_height, params.label_width, 1]\n",
    "        self.in_kstrides = [1, 10, 10, 1]\n",
    "        self.out_kstrides = [1, 20, 20, 1]\n",
    "        self.rates = [1, 1, 1, 1]\n",
    "        \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_threads: number of parallel calls to be made while parsing\n",
    "        num_prefetch: number of batches to be pre loaded before training\n",
    "        \n",
    "    Returns:\n",
    "        Next batch to be served to model\n",
    "    \n",
    "    \"\"\"\n",
    "    def build_iterators(self, num_threads=8, num_prefetch=8):\n",
    "        def parse_fn(filename, label):\n",
    "            input_img_batch = get_img_from_file(filename, \n",
    "                                                self.in_ksizes, \n",
    "                                                self.in_kstrides, \n",
    "                                                self.rates, \n",
    "                                                self.params.input_height, \n",
    "                                                self.params.input_width, \n",
    "                                                self.params.n_channels)\n",
    "\n",
    "            ground_img_batch = get_img_from_file(label, \n",
    "                                                 self.out_ksizes, \n",
    "                                                 self.out_kstrides, \n",
    "                                                 self.rates, \n",
    "                                                 self.params.label_height, \n",
    "                                                 self.params.label_width, \n",
    "                                                 self.params.n_channels)\n",
    "\n",
    "            return [input_img_batch, ground_img_batch]\n",
    "        \n",
    " \n",
    "        #train dataset graph\n",
    "        filenames = self.X_train\n",
    "        labels = self.y_train\n",
    "        \n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "        \n",
    "        train_dataset = train_dataset.map(parse_fn, num_parallel_calls=num_threads)\n",
    "        train_dataset = train_dataset.apply(tf.contrib.data.unbatch())\n",
    "        train_dataset = train_dataset.shuffle(37312)\n",
    "        train_dataset = train_dataset.batch(self.params.batch_size)\n",
    "        self.train_dataset = train_dataset.prefetch(num_prefetch)\n",
    "        \n",
    "        #val dataset graph\n",
    "        filenames = self.X_test\n",
    "        labels = self.y_test\n",
    "        \n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "        val_dataset = val_dataset.shuffle(34)\n",
    "        val_dataset = val_dataset.map(parse_fn, num_parallel_calls=num_threads)\n",
    "        val_dataset = val_dataset.apply(tf.contrib.data.unbatch())\n",
    "        val_dataset = val_dataset.batch(self.params.batch_size)\n",
    "        self.val_dataset = val_dataset.prefetch(num_prefetch)\n",
    "\n",
    "        #Make iterator\n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types, \n",
    "                                                   train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "        \n",
    "        self.train_init_op = iterator.make_initializer(self.train_dataset)\n",
    "        self.val_init_op = iterator.make_initializer(self.val_dataset)\n",
    "        \n",
    "        return next_element\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8UVo8hv9upeS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from tqdm import tqdm\n",
    "from model import VDSR\n",
    "\"\"\"\n",
    "Model class for training and inference\n",
    "Contains:\n",
    "    build(): Builds the graphs\n",
    "    fit(): trains the network for params.n_epochs\n",
    "    score(): For scoring PSNR and loss on validation dataset\n",
    "    predict(): Takes the filename as arg and returns prediction.\n",
    "\"\"\"\n",
    "class Model:\n",
    "    def __init__(self, params, data_loader):\n",
    "        self.params = params\n",
    "        self.data_loader = data_loader\n",
    "        self.grad_clip = 0.001\n",
    "        \n",
    "        #Set mode to 'train' for training and 'infer' for prediction on your own images.\n",
    "        #Set this parameter before running the build function.\n",
    "        self.mode = 'train'\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    Builds the training and inference graphs\n",
    "        \n",
    "    \"\"\"\n",
    "    def build(self):\n",
    "        decay_rate = self.params.decay_rate\n",
    "        decay_steps = self.params.decay_steps\n",
    "        \n",
    "        next_element = self.data_loader.build_iterators()\n",
    "        self.y = next_element[1]\n",
    "        \n",
    "        with tf.name_scope('inference'):\n",
    "            self.input_img_placeholder = tf.placeholder(tf.float32, shape=(None, self.params.input_height, \n",
    "                                                                           self.params.input_width, \n",
    "                                                                           self.params.n_channels))\n",
    "\n",
    "        \n",
    "        with tf.name_scope('convolutional'):\n",
    "            if self.mode == 'train':\n",
    "                x = next_element[0]\n",
    "                input_image_summ = tf.summary.image('input_image', x)\n",
    "                \n",
    "            elif self.mode == 'infer':\n",
    "                x = self.input_img_placeholder\n",
    "            \n",
    "            assert(x.get_shape().as_list()[3] is 1),  \"input shape must have channels: 1, but has shape: {}\".format(x.get_shape().as_list())\n",
    "            out, self.model_summ = VDSR(x)\n",
    "            \n",
    "            r_hat, x_input = out\n",
    "            self.output = tf.add(r_hat, x_input)\n",
    "            \n",
    "            residual_img_summ = tf.summary.image('pred_img', self.output)\n",
    "            pred_image_summ = tf.summary.image('pred_residual', r_hat)\n",
    "                        \n",
    "        with tf.name_scope('loss'):\n",
    "\n",
    "            scale = self.y.get_shape().as_list()[1:3]\n",
    "\n",
    "            r = self.y - x_input\n",
    "            \n",
    "            gt_residual_summ = tf.summary.image('gt_residual', r)\n",
    "            gt_image_summ = tf.summary.image('gt_image', self.y)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(r - r_hat))\n",
    "            \n",
    "        with tf.name_scope('metrics'):\n",
    "            self.psnr = tf.reduce_mean(tf.image.psnr(self.y, self.output, max_val=1))\n",
    "            self.ssim = tf.reduce_mean(tf.image.ssim(self.y, self.output, max_val=1))\n",
    "        \n",
    "        with tf.name_scope('train'):\n",
    "            self.g_step_tensor = tf.Variable(0, trainable=False)\n",
    "            self.learning_rate = tf.placeholder(tf.float32, shape=None, name='learning_rate')\n",
    "            init_lr = self.learning_rate\n",
    "            decayed_lr = tf.train.exponential_decay(init_lr, self.g_step_tensor,\n",
    "                                                    decay_steps, decay_rate, staircase=True)\n",
    "            lr_summ = tf.summary.scalar('lr', decayed_lr)\n",
    "            \n",
    "            self.optimizer = tf.train.GradientDescentOptimizer(decayed_lr)\n",
    "            self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
    "            \n",
    "            clip_value = tf.Variable(self.grad_clip / 0.1)\n",
    "            opt_grads = [(tf.clip_by_norm(grad, clip_value), var) for grad, var in self.grads_and_vars]\n",
    "            \n",
    "            self.train_op = self.optimizer.apply_gradients(opt_grads, global_step=self.g_step_tensor)\n",
    "             \n",
    "        with tf.name_scope('performance'):\n",
    "            \n",
    "            train_loss_summ = tf.summary.scalar('train_loss', self.loss)\n",
    "            train_psnr_summ = tf.summary.scalar('train_psnr', self.psnr)\n",
    "            train_ssim_summ = tf.summary.scalar('train_ssim', self.ssim)\n",
    "            self.train_stats = tf.summary.merge([train_loss_summ, \n",
    "                                            train_psnr_summ, \n",
    "                                            train_ssim_summ])\n",
    "            \n",
    "            valid_loss_summ = tf.summary.scalar('valid_loss', self.loss)\n",
    "            valid_psnr_summ = tf.summary.scalar('valid_psnr', self.psnr)\n",
    "            valid_ssim_summ = tf.summary.scalar('valid_ssim', self.ssim)\n",
    "            self.valid_stats = tf.summary.merge([valid_loss_summ, \n",
    "                                            valid_psnr_summ, \n",
    "                                            valid_ssim_summ])\n",
    "            grads_summ = []\n",
    "            l2_norm = lambda t: tf.sqrt(tf.reduce_sum(tf.pow(t, 2)))\n",
    "            \n",
    "            for gv in opt_grads:\n",
    "                name = gv[1].name.replace(':', '_')\n",
    "                grads_summ.append(tf.summary.scalar(name, l2_norm(gv[1])))\n",
    "                    \n",
    "            self.performance_summ = tf.summary.merge([grads_summ, lr_summ])\n",
    "            self.image_stats = tf.summary.merge([gt_image_summ, \n",
    "                                                 input_image_summ, \n",
    "                                                 pred_image_summ, \n",
    "                                                 residual_img_summ, \n",
    "                                                 gt_residual_summ])\n",
    "\n",
    "    def fit(self, lr, summ_writer):\n",
    "        epochs = self.params.n_epochs\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "            #saver.restore(sess, 'dense_models/srcnn_0.0007.ckpt')\n",
    "            summ_writer.add_graph(sess.graph)\n",
    "            \n",
    "            val_losses = [1000.0]\n",
    "            for epoch in range(epochs):\n",
    "                train_len = 583\n",
    "                loss_all = []\n",
    "                psnr_all = []\n",
    "                \n",
    "                \n",
    "                print('\\n**************************')\n",
    "                print('Epoch: ' + str(epoch))\n",
    "                with tqdm(total=train_len) as pbar:\n",
    "                    sess.run(self.data_loader.train_init_op)\n",
    "                    \n",
    "                    for steps in range(train_len):\n",
    "                        train, loss, psnr, mod_summ, train_summ, perf_summ, image_summ = sess.run([self.train_op, \n",
    "                                                                                         self.loss, \n",
    "                                                                                         self.psnr, \n",
    "                                                                                         self.model_summ,\n",
    "                                                                                         self.train_stats, \n",
    "                                                                                         self.performance_summ,\n",
    "                                                                                         self.image_stats], \n",
    "                                                                                         feed_dict={self.learning_rate: lr})\n",
    "                        \n",
    "                        \n",
    "                        summ_writer.add_summary(train_summ, global_step=tf.train.global_step(sess, self.g_step_tensor))\n",
    "                        summ_writer.add_summary(perf_summ, global_step=tf.train.global_step(sess, self.g_step_tensor))\n",
    "                        summ_writer.add_summary(image_summ, global_step=tf.train.global_step(sess, self.g_step_tensor))\n",
    "                        summ_writer.add_summary(mod_summ, global_step=tf.train.global_step(sess, self.g_step_tensor))\n",
    "                        \n",
    "                        loss_all.append(loss)\n",
    "                        psnr_all.append(psnr)\n",
    "                        pbar.set_description('loss: {:.4f} -- psnr: {:.4f}'.format(float(loss), psnr))\n",
    "                        pbar.update(1)\n",
    "                    \n",
    "                print('train_loss: {:.4f} -- train_psnr: {:.4f}'.format(np.mean(loss_all), \n",
    "                                                                        np.mean(psnr_all)))\n",
    "                \n",
    "\n",
    "                print('lr:{}'.format(lr))\n",
    "                \n",
    "                \n",
    "                val_loss = self.score(sess)\n",
    "                valid_summ = sess.run(self.valid_stats)\n",
    "                summ_writer.add_summary(valid_summ, global_step=tf.train.global_step(sess, self.g_step_tensor))\n",
    "                \n",
    "                if val_loss < min(val_losses):\n",
    "                    print('Saving model with val_loss: {:.4f} to file: unnamed_cnn_{:.4f}.ckpt'.format(val_loss,\n",
    "                                                                                                 val_loss))\n",
    "                    saver.save(sess, 'dense_models/unnamed_cnn_{:.4f}.ckpt'.format(val_loss))\n",
    "                else:\n",
    "                    print('val_loss did not improve from last best: {:.4}'.format(min(val_losses)))\n",
    "                print('**************************\\n')\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "    def score(self, session):\n",
    "\n",
    "        with session.as_default():\n",
    "\n",
    "            test_len = 34\n",
    "\n",
    "            loss_all = []\n",
    "            psnr_all = []\n",
    "\n",
    "            with tqdm(total=test_len) as pbar:\n",
    "                session.run(self.data_loader.val_init_op)\n",
    "\n",
    "                for steps in range(test_len):\n",
    "                    loss, psnr = session.run([self.loss, self.psnr])\n",
    "\n",
    "                    loss_all.append(loss)\n",
    "                    psnr_all.append(psnr)\n",
    "\n",
    "                    pbar.set_description('val_loss: {:.4f} -- val_psnr: {:.4f}'.format(loss, psnr))\n",
    "                    pbar.update(1)\n",
    "\n",
    "            print('val_loss: ' + str(np.mean(loss_all)), ' -- val_psnr: ' + str(np.mean(psnr_all)))\n",
    "            return np.mean(loss_all)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYktgrDfupeU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(X_train, y_train, X_test, y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5377,
     "status": "ok",
     "timestamp": 1549968517272,
     "user": {
      "displayName": "Ishan Shukla",
      "photoUrl": "",
      "userId": "07111032317237931620"
     },
     "user_tz": -330
    },
    "id": "bwZgsUoUupeX",
    "outputId": "ddf692f9-fec3-45c6-cf0f-a4a282f60f0a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model(params, data_loader)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10434,
     "status": "error",
     "timestamp": 1549969833392,
     "user": {
      "displayName": "Ishan Shukla",
      "photoUrl": "",
      "userId": "07111032317237931620"
     },
     "user_tz": -330
    },
    "id": "nkismnMEupea",
    "outputId": "6d2a8add-53ed-4584-ee41-ae0c050b3328",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0035 -- psnr: 26.4550: 100%|██████████| 583/583 [12:47<00:00,  1.08s/it]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0073 -- train_psnr: 24.7373\n",
      "lr:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0056 -- val_psnr: 22.9681: 100%|██████████| 34/34 [00:03<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0034683142  -- val_psnr: 26.281527\n",
      "Saving model with val_loss: 0.0035 to file: unnamed_cnn_0.0035.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************\n",
      "\n",
      "\n",
      "**************************\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0031 -- psnr: 27.3506: 100%|██████████| 583/583 [12:36<00:00,  1.04s/it]\n",
      "val_loss: 0.0026 -- val_psnr: 26.2876:   3%|▎         | 1/34 [00:00<00:03,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0046 -- train_psnr: 25.7212\n",
      "lr:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0051 -- val_psnr: 23.4470: 100%|██████████| 34/34 [00:02<00:00, 11.44it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0031916953  -- val_psnr: 26.863146\n",
      "Saving model with val_loss: 0.0032 to file: unnamed_cnn_0.0032.ckpt\n",
      "**************************\n",
      "\n",
      "\n",
      "**************************\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0029 -- psnr: 27.8077: 100%|██████████| 583/583 [12:28<00:00,  1.04s/it]\n",
      "val_loss: 0.0025 -- val_psnr: 26.5347:   3%|▎         | 1/34 [00:00<00:03,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0043 -- train_psnr: 26.0488\n",
      "lr:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0048 -- val_psnr: 23.7537: 100%|██████████| 34/34 [00:02<00:00, 11.50it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.0030639241  -- val_psnr: 27.182667\n",
      "Saving model with val_loss: 0.0031 to file: unnamed_cnn_0.0031.ckpt\n",
      "**************************\n",
      "\n",
      "\n",
      "**************************\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0044 -- psnr: 26.1277:   5%|▌         | 31/583 [00:41<11:37,  1.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ff84ec097f52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhparam_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lr_{:}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'summaries/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhparam_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-78fe5380026f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lr, summ_writer)\u001b[0m\n\u001b[1;32m    144\u001b[0m                                                                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformance_summ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                                                                                          self.image_stats], \n\u001b[0;32m--> 146\u001b[0;31m                                                                                          feed_dict={self.learning_rate: lr})\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Lr search\n",
    "for lr in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    hparam_str = 'lr_{:}'.format(lr)\n",
    "    writer = tf.summary.FileWriter('summaries/' + hparam_str)\n",
    "    model.fit(lr, writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAYwXm_tupef"
   },
   "outputs": [],
   "source": [
    "element = data_loader.build_iterators()\n",
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(), data_loader.train_init_op])\n",
    "    for i in range(3):\n",
    "        elements = sess.run(element)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yv50USUupei",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(50, 70):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(elements[0][i])\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(elements[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oiFDc85Zupel",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCYDt7s0upem"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEMkSh2Zuper"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ju61otC-upeu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxoA7VlEupew"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeuNfZw9upez"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlMFdcM5vRDx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#!wget \"https://uofi.box.com/shared/static/kfahv87nfe8ax910l85dksyl2q212voc.zip\" Set5\n",
    "!wget \"https://uofi.box.com/shared/static/65upg43jjd0a4cwsiqgl6o6ixube6klm.zip\"\n",
    "!wget \"https://uofi.box.com/shared/static/igsnfieh4lz68l926l8xbklwsnnk8we9.zip\"\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "for file in os.listdir():\n",
    "  print(file)\n",
    "  if file == 'igsnfieh4lz68l926l8xbklwsnnk8we9.zip' or file == '65upg43jjd0a4cwsiqgl6o6ixube6klm.zip':\n",
    "    zip_ref = zipfile.ZipFile(file, 'r')\n",
    "    zip_ref.extractall()\n",
    "    zip_ref.close()\n",
    "    \n",
    "\n",
    "!mkdir train\n",
    "!mv image_SRF_2 train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yRupsHuwAhB"
   },
   "outputs": [],
   "source": [
    "#Tensorboard\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEV8VDbUwxv3"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = './summaries/'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pa4bmHQLxgCS"
   },
   "outputs": [],
   "source": [
    "!rm -r summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O80-CC4IhuKc"
   },
   "outputs": [],
   "source": [
    "!mkdir 'summaries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YkD8zZUhQIJ3",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yH_HwXu10DmF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "super_res_1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
